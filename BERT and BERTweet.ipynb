{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !pip install torch torchvision\n",
    "# !pip install transformers\n",
    "# !pip3 install nltk emoji==0.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "# utils\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#visualize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modeling\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reader functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to read our already pre-processed data\n",
    "def reader_df(topic):\n",
    "  path_train = \"cleaned_df/stance_\" + topic + \"_train_cleaned.csv\"\n",
    "  path_test = \"cleaned_df/stance_\" + topic + \"_test_cleaned.csv\"\n",
    "  path_val = \"cleaned_df/stance_\" + topic + \"_validation_cleaned.csv\"\n",
    "  df_train = pd.read_csv(path_train)\n",
    "  df_val = pd.read_csv(path_val)\n",
    "  df_test = pd.read_csv(path_test)\n",
    "\n",
    "  X_train = df_train.loc[:, 'text'].values\n",
    "  y_train = df_train.loc[:, 'label'].values\n",
    "\n",
    "  X_test = df_test.loc[:, 'text'].values\n",
    "  y_test = df_test.loc[:, 'label'].values\n",
    "\n",
    "  X_val = df_val.loc[:, 'text'].values\n",
    "  y_val = df_val.loc[:, 'label'].values\n",
    "\n",
    "  return X_train, X_test, y_train, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During finetuning, we might want to use the specific tokenizer functions of BERT models, so we define a function to read the raw data.\n",
    "def raw_reader_and_tokenize(topic):\n",
    "    path_X_train = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/train_text.txt\"\n",
    "    path_X_test = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/test_text.txt\"\n",
    "    path_X_val = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/val_text.txt\"\n",
    "    path_y_train = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/train_labels.txt\"\n",
    "    path_y_test = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/test_labels.txt\"\n",
    "    path_y_val = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/stance/\" + topic + \"/val_labels.txt\"\n",
    "\n",
    "    X_train = pd.read_table(path_X_train, header=None)\n",
    "    X_test = pd.read_table(path_X_test, header=None)\n",
    "    X_val = pd.read_table(path_X_val, header=None)\n",
    "    y_train = pd.read_table(path_y_train, header=None)\n",
    "    y_test = pd.read_table(path_y_test, header=None)\n",
    "    y_val = pd.read_table(path_y_val, header=None)\n",
    "\n",
    "    X_train = X_train.rename(columns={0: \"text\"})\n",
    "    X_test = X_test.rename(columns={0: \"text\"})\n",
    "    y_train = y_train.rename(columns={0: \"label\"})\n",
    "    y_test = y_test.rename(columns={0: \"label\"})\n",
    "    X_val = X_val.rename(columns={0: \"text\"})\n",
    "    y_val = y_val.rename(columns={0: \"label\"})\n",
    "\n",
    "    # Convert the DataFrame to a Hugging Face Dataset\n",
    "    train_dataset = Dataset.from_dict({\"text\": X_train[\"text\"].values, \"label\": y_train[\"label\"].values})\n",
    "    val_dataset = Dataset.from_dict({\"text\": X_val[\"text\"].values, \"label\": y_val[\"label\"].values})\n",
    "    test_dataset = Dataset.from_dict({\"text\": X_test[\"text\"].values, \"label\": y_test[\"label\"].values})\n",
    "\n",
    "    # Tokenize the training and validation datasets\n",
    "    train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "    val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "    test_dataset = test_dataset.map(tokenize, batched=True, batch_size=len(test_dataset))\n",
    "\n",
    "    # Set the format of the datasets to PyTorch tensors\n",
    "    train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **DistilBERT** model\n",
    "\n",
    "As a first test, we can calculate how accurate the predictions are using a DistilBert model. The code below uses `DistilBertTokenizerFast` on our already pre-processed datasets. \n",
    "We apply the `DistilBertForSequenceClassification` model, which is the most appropiate for our current task of multi-class classification.\n",
    "\n",
    "We will implement this first model in the `stances-feminist` dataset, just to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from sklearn.metrics import f1_score, precision_score, accuracy_score\n",
    "import torch\n",
    "\n",
    "X_train, X_test, y_train, y_test, X_val, y_val = reader_df(\"feminist\")\n",
    "\n",
    "\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n",
    "\n",
    "# Prepare the data\n",
    "train_texts = X_train.tolist() \n",
    "train_labels = y_train.tolist()\n",
    "test_texts = X_test.tolist()\n",
    "test_labels = y_test.tolist()\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(train_texts, return_tensors='pt', padding=True, truncation=True)\n",
    "test_encodings = tokenizer(test_texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Convert to torch Dataset\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, train_labels)\n",
    "test_dataset = TweetDataset(test_encodings, test_labels)\n",
    "\n",
    "# Train the model\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') # useful to improve computing time, depending on our pc characteristics\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below we use the PyTorch library to create a DataLoader object for the train_dataset with a batch size of 16. This means that the data in train_dataset will be divided into batches of 16 samples each and fed into the model for training.\n",
    "We also create an Adam optimizer object with a learning rate of 5e-5. The optimizer is used to update the modelâ€™s parameters during training to minimize the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\danid\\AppData\\Local\\Temp\\ipykernel_18520\\2094193682.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.5426585516619846\n",
      "Precision: 0.6004088504088504\n",
      "Accuracy: 0.5719298245614035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16)\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs[0]\n",
    "        predictions.extend(logits.argmax(dim=-1).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "f1 = f1_score(true_labels, predictions, average='macro')\n",
    "precision = precision_score(true_labels, predictions, average='macro')\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "print(f'F1 score: {f1}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an F1 of 54 with this implementation. How can we improve this?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuned BERTweet implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT is a pre-trained language model that has been shown to achieve state-of-the-art performance on a wide range of natural language processing tasks. However, BERT was pre-trained on a large corpus of general text, which may not be representative of the language used in tweets.\n",
    "\n",
    "Tweets are known to have unique characteristics that can make them more challenging to classify compared to other types of text. For example, tweets are often shorter, contain a lot of noise (such as typos and slang), and can have complex grammatical structures that are not found in more formal writing.\n",
    "\n",
    "Additionally, the use of hashtags, emojis, and other special characters in tweets can make it difficult for BERT to understand the context and sentiment of the tweet. Pre-processing and cleaning the tweets can help to mitigate some of these issues, but there is still a limit to the effectiveness of this approach.\n",
    "\n",
    "To address these challenges, researchers have developed specialized versions of BERT for use with social media data. For example, BERTweet is a variant of BERT that has been trained specifically on tweets and has been shown to outperform generic BERT on tweet classification tasks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **BERTweet**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define a `compute_metrics` function that calls precision, recall and F1, using a macro average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danid\\AppData\\Local\\Temp\\ipykernel_17104\\895855993.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  precision = load_metric(\"precision\")\n"
     ]
    }
   ],
   "source": [
    "precision = load_metric(\"precision\")\n",
    "recall = load_metric(\"recall\")\n",
    "f1 = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"precision\": precision.compute(predictions=predictions, references=labels, average=\"macro\"),\n",
    "        \"recall\": recall.compute(predictions=predictions, references=labels, average=\"macro\"),\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels, average=\"macro\"),\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the tokenizer from Bertweet, and implement the five models after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERTweet tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True)\n",
    "\n",
    "# Define a function to tokenize the dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance: climate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, instead of our pre-processed datasets, we will import the raw data.\n",
    "(As a note, we tried an implementation using our pre-processed datasets, but the scores were slightly worse in all cases. For this alternative implementation, see code that is commented out below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5237ef3fe048c98100e83e566d8d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/355 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5b34f86776453a91d538fe6a2652ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c109a0c08f524133afd9d303ad186508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"climate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ALTERNATIVE IMPLEMENTATION WITH OUR PRE-PROCESSED DATA, INSTEAD OF RAW DATA\n",
    "\n",
    "# Convert the DataFrame to a Hugging Face Dataset\n",
    "# X_train, X_test, y_train, y_test, X_val, y_val = reader_df(\"climate\")\n",
    "\n",
    "# train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "# val_dataset = Dataset.from_dict({\"text\": X_val, \"label\": y_val})\n",
    "# test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "# # Tokenize the training and validation datasets\n",
    "# train_dataset = train_dataset.map(tokenize, batched=True, batch_size=len(train_dataset))\n",
    "# val_dataset = val_dataset.map(tokenize, batched=True, batch_size=len(val_dataset))\n",
    "\n",
    "# # Set the format of the datasets to PyTorch tensors\n",
    "# train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "# val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\danid/.cache\\huggingface\\hub\\models--vinai--bertweet-base\\snapshots\\118ab1d567653bec16bbb081eafb6f8942f72108\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"vinai/bertweet-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\danid/.cache\\huggingface\\hub\\models--vinai--bertweet-base\\snapshots\\118ab1d567653bec16bbb081eafb6f8942f72108\\pytorch_model.bin\n",
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 355\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60\n",
      "  Number of trainable parameters = 134902275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abeb6cde52514c9db7b84eefd65bee7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4f51854cf14fb6b6dfc9d8544b8ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5839727195225916}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6115779645191409}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5971479500891265}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-12\n",
      "Configuration saved in ./results\\checkpoint-12\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5253016352653503, 'eval_precision': {'precision': 0.5839727195225916}, 'eval_recall': {'recall': 0.6115779645191409}, 'eval_f1': {'f1': 0.5971479500891265}, 'eval_runtime': 1.7267, 'eval_samples_per_second': 23.166, 'eval_steps_per_second': 1.158, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-12\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3706c883ffdf48d585e9bd00ff814d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5444096133751306}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5294117647058824}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.518095238095238}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-24\n",
      "Configuration saved in ./results\\checkpoint-24\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6195958852767944, 'eval_precision': {'precision': 0.5444096133751306}, 'eval_recall': {'recall': 0.5294117647058824}, 'eval_f1': {'f1': 0.518095238095238}, 'eval_runtime': 1.9658, 'eval_samples_per_second': 20.348, 'eval_steps_per_second': 1.017, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-24\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0989051afe81401fa32089bff6d7a608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6041666666666666}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6274509803921569}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6141414141414141}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-36\n",
      "Configuration saved in ./results\\checkpoint-36\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4208868443965912, 'eval_precision': {'precision': 0.6041666666666666}, 'eval_recall': {'recall': 0.6274509803921569}, 'eval_f1': {'f1': 0.6141414141414141}, 'eval_runtime': 1.6987, 'eval_samples_per_second': 23.548, 'eval_steps_per_second': 1.177, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-36\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1708909cabb44e5a85733c17bf75ddac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6041666666666666}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6274509803921569}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6141414141414141}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-48\n",
      "Configuration saved in ./results\\checkpoint-48\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3590737581253052, 'eval_precision': {'precision': 0.6041666666666666}, 'eval_recall': {'recall': 0.6274509803921569}, 'eval_f1': {'f1': 0.6141414141414141}, 'eval_runtime': 1.6977, 'eval_samples_per_second': 23.561, 'eval_steps_per_second': 1.178, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-48\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 40\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deec72421a944b08aad12c33ecb57d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.6041666666666666}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6274509803921569}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6141414141414141}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-60\n",
      "Configuration saved in ./results\\checkpoint-60\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37791839241981506, 'eval_precision': {'precision': 0.6041666666666666}, 'eval_recall': {'recall': 0.6274509803921569}, 'eval_f1': {'f1': 0.6141414141414141}, 'eval_runtime': 1.7367, 'eval_samples_per_second': 23.032, 'eval_steps_per_second': 1.152, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-60\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-48 (score: 0.3590737581253052).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 333.8925, 'train_samples_per_second': 5.316, 'train_steps_per_second': 0.18, 'train_loss': 0.48289686838785806, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.48289686838785806, metrics={'train_runtime': 333.8925, 'train_samples_per_second': 5.316, 'train_steps_per_second': 0.18, 'train_loss': 0.48289686838785806, 'epoch': 5.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained BERTweet model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=3)\n",
    "\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 169\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bbc5d3f9ba4941b6b1d1b0b2406138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.5184569952011812}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5770034843205575}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5450520028833282}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the trained model in the test set\n",
    "\n",
    "# trainer.compute_metrics=compute_metrics\n",
    "# (if we want to use different metrics (e.g. weighted average), just update the compute_metrics function\n",
    "#  and run the line above)\n",
    "results = trainer.evaluate(test_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5184569952011812}\n",
      "{'recall': 0.5770034843205575}\n",
      "{'f1': 0.5450520028833282}\n"
     ]
    }
   ],
   "source": [
    "print(results[\"eval_precision\"])\n",
    "print(results[\"eval_recall\"])\n",
    "print(results[\"eval_f1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess possible biases, we can check how well we are predicting each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 169\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871955b76468400f922b05d3c934ebd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Precision: 0.6744186046511628\n",
      "Recall: 0.8285714285714286\n",
      "F1-score: 0.7435897435897435\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.8809523809523809\n",
      "Recall: 0.9024390243902439\n",
      "F1-score: 0.8915662650602411\n",
      "\n",
      "Class: macro avg\n",
      "Precision: 0.5184569952011812\n",
      "Recall: 0.5770034843205575\n",
      "F1-score: 0.5450520028833282\n",
      "\n",
      "Class: weighted avg\n",
      "Precision: 0.7808390178694293\n",
      "Recall: 0.8284023668639053\n",
      "F1-score: 0.8028892995742644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions = trainer.predict(test_dataset).predictions\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(test_dataset['label'], test_predictions, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for label in report:\n",
    "    if label != 'accuracy':\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"Precision: {report[label]['precision']}\")\n",
    "        print(f\"Recall: {report[label]['recall']}\")\n",
    "        print(f\"F1-score: {report[label]['f1-score']}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare with the original benchmarking methodology, we take the average of F1 scores for against and favor clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 - Stance CLIMATE: 0.44578313253012053\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "f1_against = report['1']['f1-score']\n",
    "f1_favor = report['2']['f1-score']\n",
    "tweeteval_result = (f1_against+f1_favor) / 2\n",
    "print(\"Final F1 - Stance CLIMATE: \" + str(tweeteval_result))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stance: atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c79fecd9834ad1b0f7664d3dc54773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/461 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d120772e5e8c4816a98c903d4a1c562d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/52 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1196723d1fea4ee18a26cb677931bc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/220 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 461\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 75\n",
      "  Number of trainable parameters = 134902275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057cc1c0f42c41a8976d5949bcb84ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 52\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7aa89c4aae4e439378217bff9de594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.4794326241134752}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.4336917562724014}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.41327300150829566}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-15\n",
      "Configuration saved in ./results\\checkpoint-15\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.957466185092926, 'eval_precision': {'precision': 0.4794326241134752}, 'eval_recall': {'recall': 0.4336917562724014}, 'eval_f1': {'f1': 0.41327300150829566}, 'eval_runtime': 2.4984, 'eval_samples_per_second': 20.814, 'eval_steps_per_second': 0.801, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-15\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 52\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3845b9dfa5ab4ae09e5d2ce0e73a72f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.646011396011396}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5433094384707288}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5493386243386243}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-30\n",
      "Configuration saved in ./results\\checkpoint-30\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.744162917137146, 'eval_precision': {'precision': 0.646011396011396}, 'eval_recall': {'recall': 0.5433094384707288}, 'eval_f1': {'f1': 0.5493386243386243}, 'eval_runtime': 2.4655, 'eval_samples_per_second': 21.091, 'eval_steps_per_second': 0.811, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-30\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 52\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ada16094ff24447b44affdedfe37ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6708333333333334}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6684587813620072}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6674767727399306}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-45\n",
      "Configuration saved in ./results\\checkpoint-45\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6782239079475403, 'eval_precision': {'precision': 0.6708333333333334}, 'eval_recall': {'recall': 0.6684587813620072}, 'eval_f1': {'f1': 0.6674767727399306}, 'eval_runtime': 2.4587, 'eval_samples_per_second': 21.149, 'eval_steps_per_second': 0.813, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-45\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 52\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a05e5ff54bf43a6ab9bc9746df5e823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7523809523809524}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6899641577060932}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7038809144072302}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-60\n",
      "Configuration saved in ./results\\checkpoint-60\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7633729577064514, 'eval_precision': {'precision': 0.7523809523809524}, 'eval_recall': {'recall': 0.6899641577060932}, 'eval_f1': {'f1': 0.7038809144072302}, 'eval_runtime': 2.4514, 'eval_samples_per_second': 21.213, 'eval_steps_per_second': 0.816, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-60\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 52\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2358461d440429ba54cf5df503ed522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7293650793650794}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7425328554360813}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7160370634354954}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-75\n",
      "Configuration saved in ./results\\checkpoint-75\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.758226752281189, 'eval_precision': {'precision': 0.7293650793650794}, 'eval_recall': {'recall': 0.7425328554360813}, 'eval_f1': {'f1': 0.7160370634354954}, 'eval_runtime': 2.3626, 'eval_samples_per_second': 22.009, 'eval_steps_per_second': 0.847, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-75\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-45 (score: 0.6782239079475403).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 220\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 411.1427, 'train_samples_per_second': 5.606, 'train_steps_per_second': 0.182, 'train_loss': 0.5718584187825521, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e638bbf3af486e8bb0a206f5451064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Precision: 0.5348837209302325\n",
      "Recall: 0.8214285714285714\n",
      "F1-score: 0.647887323943662\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.9\n",
      "Recall: 0.7875\n",
      "F1-score: 0.84\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.5405405405405406\n",
      "Recall: 0.625\n",
      "F1-score: 0.5797101449275363\n",
      "\n",
      "Class: macro avg\n",
      "Precision: 0.658474753823591\n",
      "Recall: 0.744642857142857\n",
      "F1-score: 0.6891991562903993\n",
      "\n",
      "Class: weighted avg\n",
      "Precision: 0.8012456431061082\n",
      "Recall: 0.7681818181818182\n",
      "F1-score: 0.7776889532186532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"atheism\")\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions = trainer.predict(test_dataset).predictions\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(test_dataset['label'], test_predictions, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for label in report:\n",
    "    if label != 'accuracy':\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"Precision: {report[label]['precision']}\")\n",
    "        print(f\"Recall: {report[label]['recall']}\")\n",
    "        print(f\"F1-score: {report[label]['f1-score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 - Stance ATHEISM: 0.7098550724637681\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "f1_against = report['1']['f1-score']\n",
    "f1_favor = report['2']['f1-score']\n",
    "tweeteval_result_atheism = (f1_against+f1_favor) / 2\n",
    "print(\"Final F1 - Stance ATHEISM: \" + str(tweeteval_result_atheism))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance: feminist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d5dd47e0f4446b9fef6d5e37a549b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/597 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d837f6b1e704ad5bba2e702446eee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4ed61e00ae44648521ee57724690fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 597\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 95\n",
      "  Number of trainable parameters = 134902275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac7e64b4c7c460fa27ff476b61168e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486c412653974130bd46cf8ea2aed9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6662768031189084}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5153735153735154}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.47222222222222215}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-19\n",
      "Configuration saved in ./results\\checkpoint-19\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8846456408500671, 'eval_precision': {'precision': 0.6662768031189084}, 'eval_recall': {'recall': 0.5153735153735154}, 'eval_f1': {'f1': 0.47222222222222215}, 'eval_runtime': 4.9132, 'eval_samples_per_second': 13.637, 'eval_steps_per_second': 0.611, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-19\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b1a388311f4b919ca58817a3f04965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5913521176679072}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.558996558996559}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5519460851128275}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-38\n",
      "Configuration saved in ./results\\checkpoint-38\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9805386662483215, 'eval_precision': {'precision': 0.5913521176679072}, 'eval_recall': {'recall': 0.558996558996559}, 'eval_f1': {'f1': 0.5519460851128275}, 'eval_runtime': 4.5639, 'eval_samples_per_second': 14.68, 'eval_steps_per_second': 0.657, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-38\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83df49946cab451392da862b1912c383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5841491841491842}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5275835275835276}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5294920133629811}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-57\n",
      "Configuration saved in ./results\\checkpoint-57\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.03778076171875, 'eval_precision': {'precision': 0.5841491841491842}, 'eval_recall': {'recall': 0.5275835275835276}, 'eval_f1': {'f1': 0.5294920133629811}, 'eval_runtime': 4.4445, 'eval_samples_per_second': 15.075, 'eval_steps_per_second': 0.675, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-57\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7f9f4c70e14daaa913390e64695db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5459595959595959}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5308025308025308}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5369093908330388}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-76\n",
      "Configuration saved in ./results\\checkpoint-76\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9985182881355286, 'eval_precision': {'precision': 0.5459595959595959}, 'eval_recall': {'recall': 0.5308025308025308}, 'eval_f1': {'f1': 0.5369093908330388}, 'eval_runtime': 4.3904, 'eval_samples_per_second': 15.26, 'eval_steps_per_second': 0.683, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-76\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cb3f04459f4ff9be910129ae892aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.5438228438228437}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.5481185481185481}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.5421310368118878}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-95\n",
      "Configuration saved in ./results\\checkpoint-95\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0821036100387573, 'eval_precision': {'precision': 0.5438228438228437}, 'eval_recall': {'recall': 0.5481185481185481}, 'eval_f1': {'f1': 0.5421310368118878}, 'eval_runtime': 4.415, 'eval_samples_per_second': 15.176, 'eval_steps_per_second': 0.68, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-95\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-19 (score: 0.8846456408500671).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 285\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 735.8505, 'train_samples_per_second': 4.057, 'train_steps_per_second': 0.129, 'train_loss': 0.6242399115311472, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0f7d14bbd44287b40e3805095f78fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Precision: 0.49206349206349204\n",
      "Recall: 0.7045454545454546\n",
      "F1-score: 0.5794392523364486\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.7156398104265402\n",
      "Recall: 0.825136612021858\n",
      "F1-score: 0.766497461928934\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.36363636363636365\n",
      "Recall: 0.06896551724137931\n",
      "F1-score: 0.11594202898550723\n",
      "\n",
      "Class: macro avg\n",
      "Precision: 0.5237798887087987\n",
      "Recall: 0.5328825279362306\n",
      "F1-score: 0.48729291441696326\n",
      "\n",
      "Class: weighted avg\n",
      "Precision: 0.6094869756131915\n",
      "Recall: 0.6526315789473685\n",
      "F1-score: 0.6052245625156423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"feminist\")\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions = trainer.predict(test_dataset).predictions\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(test_dataset['label'], test_predictions, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for label in report:\n",
    "    if label != 'accuracy':\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"Precision: {report[label]['precision']}\")\n",
    "        print(f\"Recall: {report[label]['recall']}\")\n",
    "        print(f\"F1-score: {report[label]['f1-score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 - Stance FEMINIST: 0.4412197454572206\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "f1_against = report['1']['f1-score']\n",
    "f1_favor = report['2']['f1-score']\n",
    "tweeteval_result_feminist = (f1_against+f1_favor) / 2\n",
    "print(\"Final F1 - Stance FEMINIST: \" + str(tweeteval_result_feminist))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance: Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84e730cdf3f42b2b6d196d1491a16dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/587 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25530f203644912a3443714e3f9f98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6788a285356b45a19b07876329286055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 95\n",
      "  Number of trainable parameters = 134902275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f4702eeec04cdfa88ccaefbab70dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2eb4156831147ee9ede4fdb4bbaaa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7359788359788361}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6851851851851851}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7034077034077034}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-19\n",
      "Configuration saved in ./results\\checkpoint-19\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6615263223648071, 'eval_precision': {'precision': 0.7359788359788361}, 'eval_recall': {'recall': 0.6851851851851851}, 'eval_f1': {'f1': 0.7034077034077034}, 'eval_runtime': 2.8533, 'eval_samples_per_second': 23.131, 'eval_steps_per_second': 1.051, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-19\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0358f0ee87a24abd9ef592d6ecfd9e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7171877760113055}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7129629629629629}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.714851054577082}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-38\n",
      "Configuration saved in ./results\\checkpoint-38\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6878447532653809, 'eval_precision': {'precision': 0.7171877760113055}, 'eval_recall': {'recall': 0.7129629629629629}, 'eval_f1': {'f1': 0.714851054577082}, 'eval_runtime': 3.2953, 'eval_samples_per_second': 20.029, 'eval_steps_per_second': 0.91, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-38\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1393f8e4151c466f8987a641ff25cec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6828282828282828}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7037037037037037}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6902844873859366}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-57\n",
      "Configuration saved in ./results\\checkpoint-57\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6775017976760864, 'eval_precision': {'precision': 0.6828282828282828}, 'eval_recall': {'recall': 0.7037037037037037}, 'eval_f1': {'f1': 0.6902844873859366}, 'eval_runtime': 2.7448, 'eval_samples_per_second': 24.045, 'eval_steps_per_second': 1.093, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-57\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbebf0ec1186479c8100f19f54089a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6633986928104575}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.6759259259259259}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6683760683760683}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-76\n",
      "Configuration saved in ./results\\checkpoint-76\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6935228109359741, 'eval_precision': {'precision': 0.6633986928104575}, 'eval_recall': {'recall': 0.6759259259259259}, 'eval_f1': {'f1': 0.6683760683760683}, 'eval_runtime': 3.3371, 'eval_samples_per_second': 19.778, 'eval_steps_per_second': 0.899, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-76\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f943b9b63641c583f4195012fe73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7282765737874097}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7777777777777777}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7378578410836475}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-95\n",
      "Configuration saved in ./results\\checkpoint-95\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7481910586357117, 'eval_precision': {'precision': 0.7282765737874097}, 'eval_recall': {'recall': 0.7777777777777777}, 'eval_f1': {'f1': 0.7378578410836475}, 'eval_runtime': 3.1779, 'eval_samples_per_second': 20.768, 'eval_steps_per_second': 0.944, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-95\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-19 (score: 0.6615263223648071).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 280\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 899.8938, 'train_samples_per_second': 3.261, 'train_steps_per_second': 0.106, 'train_loss': 0.4689614145379317, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c071e9903a3c443b9f38ba1c1fe83e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Precision: 0.45454545454545453\n",
      "Recall: 0.7777777777777778\n",
      "F1-score: 0.5737704918032788\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.7722222222222223\n",
      "Recall: 0.7354497354497355\n",
      "F1-score: 0.7533875338753387\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.4782608695652174\n",
      "Recall: 0.2391304347826087\n",
      "F1-score: 0.3188405797101449\n",
      "\n",
      "Class: macro avg\n",
      "Precision: 0.5683428487776313\n",
      "Recall: 0.584119316003374\n",
      "F1-score: 0.5486662017962541\n",
      "\n",
      "Class: weighted avg\n",
      "Precision: 0.6728733766233768\n",
      "Recall: 0.6607142857142857\n",
      "F1-score: 0.6531306525009043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"abortion\")\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions = trainer.predict(test_dataset).predictions\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(test_dataset['label'], test_predictions, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for label in report:\n",
    "    if label != 'accuracy':\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"Precision: {report[label]['precision']}\")\n",
    "        print(f\"Recall: {report[label]['recall']}\")\n",
    "        print(f\"F1-score: {report[label]['f1-score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 - Stance ABORTION: 0.5361140567927418\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "f1_against = report['1']['f1-score']\n",
    "f1_favor = report['2']['f1-score']\n",
    "tweeteval_result_abortion = (f1_against+f1_favor) / 2\n",
    "print(\"Final F1 - Stance ABORTION: \" + str(tweeteval_result_abortion))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stance: Hillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f5ed6c2d9548478ab14fe090681e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/587 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5111f3e1f44e858eb87e7db90eec51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/66 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2695c31f0ef84e509fe8ff6abc9309ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/280 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "c:\\Users\\danid\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 587\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 95\n",
      "  Number of trainable parameters = 134902275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5018c351a4448c5a464304b794acbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fde833152424afbb6d32b1a5db9752b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.6805555555555557}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7037037037037037}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6562289562289562}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-19\n",
      "Configuration saved in ./results\\checkpoint-19\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8476704955101013, 'eval_precision': {'precision': 0.6805555555555557}, 'eval_recall': {'recall': 0.7037037037037037}, 'eval_f1': {'f1': 0.6562289562289562}, 'eval_runtime': 2.7017, 'eval_samples_per_second': 24.43, 'eval_steps_per_second': 1.11, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-19\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068aba62311a4db69ec1e1133c7d7358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7175925925925926}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.611111111111111}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.6331569664902998}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-38\n",
      "Configuration saved in ./results\\checkpoint-38\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8007002472877502, 'eval_precision': {'precision': 0.7175925925925926}, 'eval_recall': {'recall': 0.611111111111111}, 'eval_f1': {'f1': 0.6331569664902998}, 'eval_runtime': 2.9279, 'eval_samples_per_second': 22.542, 'eval_steps_per_second': 1.025, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-38\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3085f51f072843949b23a76c495458ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7052287581699347}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7222222222222223}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7053092501368363}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-57\n",
      "Configuration saved in ./results\\checkpoint-57\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7921849489212036, 'eval_precision': {'precision': 0.7052287581699347}, 'eval_recall': {'recall': 0.7222222222222223}, 'eval_f1': {'f1': 0.7053092501368363}, 'eval_runtime': 2.7333, 'eval_samples_per_second': 24.147, 'eval_steps_per_second': 1.098, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-57\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1158a8a3958413083562b45c31f26a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.7357142857142858}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.75}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7392064807143514}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-76\n",
      "Configuration saved in ./results\\checkpoint-76\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8476834297180176, 'eval_precision': {'precision': 0.7357142857142858}, 'eval_recall': {'recall': 0.75}, 'eval_f1': {'f1': 0.7392064807143514}, 'eval_runtime': 3.0218, 'eval_samples_per_second': 21.841, 'eval_steps_per_second': 0.993, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-76\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a47a6cb2f41468baaff0f1d23d9cc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.734640522875817}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'recall': 0.7592592592592594}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'f1': 0.7378215654077723}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Saving model checkpoint to ./results\\checkpoint-95\n",
      "Configuration saved in ./results\\checkpoint-95\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8488245606422424, 'eval_precision': {'precision': 0.734640522875817}, 'eval_recall': {'recall': 0.7592592592592594}, 'eval_f1': {'f1': 0.7378215654077723}, 'eval_runtime': 3.5002, 'eval_samples_per_second': 18.856, 'eval_steps_per_second': 0.857, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-95\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-57 (score: 0.7921849489212036).\n",
      "The following columns in the test set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 280\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 520.1074, 'train_samples_per_second': 5.643, 'train_steps_per_second': 0.183, 'train_loss': 0.3170971117521587, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a102818554b74455b823a643b5a4fb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Precision: 0.5076923076923077\n",
      "Recall: 0.7333333333333333\n",
      "F1-score: 0.6\n",
      "\n",
      "Class: 1\n",
      "Precision: 0.8544303797468354\n",
      "Recall: 0.7142857142857143\n",
      "F1-score: 0.7780979827089337\n",
      "\n",
      "Class: 2\n",
      "Precision: 0.5263157894736842\n",
      "Recall: 0.6521739130434783\n",
      "F1-score: 0.5825242718446602\n",
      "\n",
      "Class: macro avg\n",
      "Precision: 0.6294794923042758\n",
      "Recall: 0.6999309868875087\n",
      "F1-score: 0.6535407515178646\n",
      "\n",
      "Class: weighted avg\n",
      "Precision: 0.7448000783360543\n",
      "Recall: 0.7071428571428572\n",
      "F1-score: 0.7173451258458674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import dataset\n",
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"abortion\")\n",
    "\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model on the training dataset\n",
    "trainer.train()\n",
    "\n",
    "# Generate predictions for the test set\n",
    "test_predictions = trainer.predict(test_dataset).predictions\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Compute the classification report\n",
    "report = classification_report(test_dataset['label'], test_predictions, output_dict=True)\n",
    "\n",
    "# Print the classification report\n",
    "for label in report:\n",
    "    if label != 'accuracy':\n",
    "        print(f\"Class: {label}\")\n",
    "        print(f\"Precision: {report[label]['precision']}\")\n",
    "        print(f\"Recall: {report[label]['recall']}\")\n",
    "        print(f\"F1-score: {report[label]['f1-score']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 - Stance HILLARY: 0.680311127276797\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "f1_against = report['1']['f1-score']\n",
    "f1_favor = report['2']['f1-score']\n",
    "tweeteval_result_hillary = (f1_against+f1_favor) / 2\n",
    "print(\"Final F1 - Stance HILLARY: \" + str(tweeteval_result_hillary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average F1 for all five datasets is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global F1 mean: 0.5626566269041297\n",
      "{'Climate': 0.44578313253012053, 'Abortion': 0.5361140567927418, 'Atheism': 0.7098550724637681, 'Feminist': 0.4412197454572206, 'Hillary': 0.680311127276797}\n"
     ]
    }
   ],
   "source": [
    "f1_all = [tweeteval_result, tweeteval_result_abortion, tweeteval_result_atheism, tweeteval_result_feminist, tweeteval_result_hillary]\n",
    "f1_all = np.array(f1_all)\n",
    "f1_all_dic = {\"Climate\":tweeteval_result, \"Abortion\": tweeteval_result_abortion, \"Atheism\": tweeteval_result_atheism, \"Feminist\": tweeteval_result_feminist, \"Hillary\": tweeteval_result_hillary}\n",
    "print(\"Global F1 mean: \" + str(np.mean(f1_all)))\n",
    "print(f1_all_dic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter search: best learning rate.\n",
    "### (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = raw_reader_and_tokenize(\"climate\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the range of learning rates to search over\n",
    "# learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "\n",
    "# # Initialize variables to store the best learning rate and validation loss\n",
    "# best_learning_rate = None\n",
    "# best_val_loss = np.inf\n",
    "\n",
    "# # Perform grid search over learning rates\n",
    "# for lr in learning_rates:\n",
    "#     # Define the training arguments\n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir='./results',\n",
    "#         evaluation_strategy='epoch',\n",
    "#         save_strategy='epoch',\n",
    "#         learning_rate=lr,\n",
    "#         per_device_train_batch_size=32,\n",
    "#         per_device_eval_batch_size=32,\n",
    "#         num_train_epochs=5,\n",
    "#         logging_dir='./logs',\n",
    "#         logging_steps=10,\n",
    "#         load_best_model_at_end=True,\n",
    "#         seed=1\n",
    "#     )\n",
    "\n",
    "#     # Create a Trainer instance\n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=training_args,\n",
    "#         train_dataset=train_dataset,\n",
    "#         eval_dataset=val_dataset\n",
    "#     )\n",
    "\n",
    "#     # Fine-tune the model on the training dataset\n",
    "#     trainer.train()\n",
    "\n",
    "#     # Evaluate the model on the validation dataset\n",
    "#     val_loss = trainer.evaluate()['eval_loss']\n",
    "\n",
    "#     # Update the best learning rate and validation loss if necessary\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_learning_rate = lr\n",
    "#         best_val_loss = val_loss\n",
    "\n",
    "# # Print the best learning rate\n",
    "# print(f\"Best learning rate: {best_learning_rate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9bf44a63aa85fc488ba2c18070365b0fdf586414cbab845f059fd6426d069d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
